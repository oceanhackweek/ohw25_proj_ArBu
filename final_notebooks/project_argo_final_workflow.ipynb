{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Ocean Hackweek 2025 - Project Argo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.11.3\n",
      "    latest version: 25.7.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /srv/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - argopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    aiohappyeyeballs-2.6.1     |     pyhd8ed1ab_0          19 KB  conda-forge\n",
      "    aiohttp-3.12.15            |  py312h8a5da7c_0         984 KB  conda-forge\n",
      "    aiosignal-1.4.0            |     pyhd8ed1ab_0          13 KB  conda-forge\n",
      "    anyio-4.10.0               |     pyhe01879c_0         132 KB  conda-forge\n",
      "    argopy-1.2.0               |     pyhd8ed1ab_0         235 KB  conda-forge\n",
      "    attrs-25.3.0               |     pyh71513ae_0          56 KB  conda-forge\n",
      "    blosc-1.21.6               |       he440d0b_1          47 KB  conda-forge\n",
      "    ca-certificates-2025.8.3   |       hbd8a1cb_0         151 KB  conda-forge\n",
      "    cached-property-1.5.2      |       hd8ed1ab_1           4 KB  conda-forge\n",
      "    cached_property-1.5.2      |     pyha770c72_1          11 KB  conda-forge\n",
      "    certifi-2025.8.3           |     pyhd8ed1ab_0         155 KB  conda-forge\n",
      "    cftime-1.6.4               |  py312hc0a28a1_1         242 KB  conda-forge\n",
      "    decorator-5.2.1            |     pyhd8ed1ab_0          14 KB  conda-forge\n",
      "    erddapy-2.2.4              |     pyhd8ed1ab_0          26 KB  conda-forge\n",
      "    exceptiongroup-1.3.0       |     pyhd8ed1ab_0          21 KB  conda-forge\n",
      "    frozenlist-1.7.0           |  py312h447239a_0          54 KB  conda-forge\n",
      "    fsspec-2025.2.0            |     pyhd8ed1ab_0         135 KB  conda-forge\n",
      "    h11-0.16.0                 |     pyhd8ed1ab_0          37 KB  conda-forge\n",
      "    h5netcdf-1.6.4             |     pyhd8ed1ab_0          47 KB  conda-forge\n",
      "    h5py-3.13.0                |nompi_py312hedeef09_100         1.3 MB  conda-forge\n",
      "    hdf4-4.2.15                |       h2a13503_7         739 KB  conda-forge\n",
      "    hdf5-1.14.3                |nompi_h2d575fe_109         3.7 MB  conda-forge\n",
      "    httpcore-1.0.9             |     pyh29332c3_0          48 KB  conda-forge\n",
      "    httpx-0.28.1               |     pyhd8ed1ab_0          62 KB  conda-forge\n",
      "    libaec-1.1.4               |       h3f801dc_0          36 KB  conda-forge\n",
      "    libblas-3.9.0              |31_h59b9bed_openblas          16 KB  conda-forge\n",
      "    libcblas-3.9.0             |31_he106b2a_openblas          16 KB  conda-forge\n",
      "    libgfortran-14.2.0         |       h69a702a_2          52 KB  conda-forge\n",
      "    libgfortran5-14.2.0        |       hf1ad2bd_2         1.4 MB  conda-forge\n",
      "    libjpeg-turbo-3.1.0        |       hb9d3cd8_0         614 KB  conda-forge\n",
      "    liblapack-3.9.0            |31_h7ac8fdf_openblas          16 KB  conda-forge\n",
      "    libnetcdf-4.9.2            |nompi_h00e09a9_116         815 KB  conda-forge\n",
      "    libopenblas-0.3.29         |pthreads_h94d23a6_0         5.6 MB  conda-forge\n",
      "    libzip-1.11.2              |       h6991a6a_0         106 KB  conda-forge\n",
      "    multidict-6.6.3            |  py312h178313f_0          95 KB  conda-forge\n",
      "    netcdf4-1.7.2              |nompi_py312h21d6d8e_101         1.1 MB  conda-forge\n",
      "    numpy-1.26.4               |  py312heda63a1_0         7.1 MB  conda-forge\n",
      "    openssl-3.5.2              |       h26f9b46_0         3.0 MB  conda-forge\n",
      "    pandas-2.3.2               |  py312hf79963d_0        14.4 MB  conda-forge\n",
      "    propcache-0.3.1            |  py312h178313f_0          53 KB  conda-forge\n",
      "    python-dateutil-2.9.0.post0|     pyhe01879c_2         228 KB  conda-forge\n",
      "    python-tzdata-2025.2       |     pyhd8ed1ab_0         141 KB  conda-forge\n",
      "    pytz-2025.2                |     pyhd8ed1ab_0         185 KB  conda-forge\n",
      "    scipy-1.16.0               |  py312hf734454_0        16.1 MB  conda-forge\n",
      "    snappy-1.2.2               |       h03e3b7b_0          45 KB  conda-forge\n",
      "    sniffio-1.3.1              |     pyhd8ed1ab_1          15 KB  conda-forge\n",
      "    xarray-2024.2.0            |     pyhd8ed1ab_0         724 KB  conda-forge\n",
      "    yarl-1.20.1                |  py312h178313f_0         146 KB  conda-forge\n",
      "    zlib-1.3.1                 |       hb9d3cd8_2          90 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        60.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiohappyeyeballs   conda-forge/noarch::aiohappyeyeballs-2.6.1-pyhd8ed1ab_0 \n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.12.15-py312h8a5da7c_0 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.4.0-pyhd8ed1ab_0 \n",
      "  anyio              conda-forge/noarch::anyio-4.10.0-pyhe01879c_0 \n",
      "  argopy             conda-forge/noarch::argopy-1.2.0-pyhd8ed1ab_0 \n",
      "  attrs              conda-forge/noarch::attrs-25.3.0-pyh71513ae_0 \n",
      "  blosc              conda-forge/linux-64::blosc-1.21.6-he440d0b_1 \n",
      "  cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1 \n",
      "  cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1 \n",
      "  cftime             conda-forge/linux-64::cftime-1.6.4-py312hc0a28a1_1 \n",
      "  decorator          conda-forge/noarch::decorator-5.2.1-pyhd8ed1ab_0 \n",
      "  erddapy            conda-forge/noarch::erddapy-2.2.4-pyhd8ed1ab_0 \n",
      "  exceptiongroup     conda-forge/noarch::exceptiongroup-1.3.0-pyhd8ed1ab_0 \n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.7.0-py312h447239a_0 \n",
      "  fsspec             conda-forge/noarch::fsspec-2025.2.0-pyhd8ed1ab_0 \n",
      "  h11                conda-forge/noarch::h11-0.16.0-pyhd8ed1ab_0 \n",
      "  h5netcdf           conda-forge/noarch::h5netcdf-1.6.4-pyhd8ed1ab_0 \n",
      "  h5py               conda-forge/linux-64::h5py-3.13.0-nompi_py312hedeef09_100 \n",
      "  hdf4               conda-forge/linux-64::hdf4-4.2.15-h2a13503_7 \n",
      "  hdf5               conda-forge/linux-64::hdf5-1.14.3-nompi_h2d575fe_109 \n",
      "  httpcore           conda-forge/noarch::httpcore-1.0.9-pyh29332c3_0 \n",
      "  httpx              conda-forge/noarch::httpx-0.28.1-pyhd8ed1ab_0 \n",
      "  libaec             conda-forge/linux-64::libaec-1.1.4-h3f801dc_0 \n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-31_h59b9bed_openblas \n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-31_he106b2a_openblas \n",
      "  libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_2 \n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hf1ad2bd_2 \n",
      "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.0-hb9d3cd8_0 \n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-31_h7ac8fdf_openblas \n",
      "  libnetcdf          conda-forge/linux-64::libnetcdf-4.9.2-nompi_h00e09a9_116 \n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.29-pthreads_h94d23a6_0 \n",
      "  libzip             conda-forge/linux-64::libzip-1.11.2-h6991a6a_0 \n",
      "  multidict          conda-forge/linux-64::multidict-6.6.3-py312h178313f_0 \n",
      "  netcdf4            conda-forge/linux-64::netcdf4-1.7.2-nompi_py312h21d6d8e_101 \n",
      "  numpy              conda-forge/linux-64::numpy-1.26.4-py312heda63a1_0 \n",
      "  pandas             conda-forge/linux-64::pandas-2.3.2-py312hf79963d_0 \n",
      "  propcache          conda-forge/linux-64::propcache-0.3.1-py312h178313f_0 \n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhe01879c_2 \n",
      "  python-tzdata      conda-forge/noarch::python-tzdata-2025.2-pyhd8ed1ab_0 \n",
      "  pytz               conda-forge/noarch::pytz-2025.2-pyhd8ed1ab_0 \n",
      "  scipy              conda-forge/linux-64::scipy-1.16.0-py312hf734454_0 \n",
      "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_0 \n",
      "  sniffio            conda-forge/noarch::sniffio-1.3.1-pyhd8ed1ab_1 \n",
      "  xarray             conda-forge/noarch::xarray-2024.2.0-pyhd8ed1ab_0 \n",
      "  yarl               conda-forge/linux-64::yarl-1.20.1-py312h178313f_0 \n",
      "  zlib               conda-forge/linux-64::zlib-1.3.1-hb9d3cd8_2 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0 \n",
      "  certifi                            2025.1.31-pyhd8ed1ab_0 --> 2025.8.3-pyhd8ed1ab_0 \n",
      "  openssl                                  3.4.1-h7b32b05_0 --> 3.5.2-h26f9b46_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "# download argopy if needed\n",
    "# ! conda install -c conda-forge argopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ohw25_proj_ArBu/final_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'argopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mccrs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcfeature\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFetcher\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timedelta\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'argopy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from argopy import DataFetcher\n",
    "from datetime import timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibt_file_path = \"/home/jovyan/shared-public/OHW25/ArBu_proj_shared/ibtracs/ibtracs.ALL.list.v04r01.csv\" # provide hurricane ibtracs data\n",
    "season= 2023 # specify hurricane season\n",
    "target_hurr = ['ADRIAN', 'HILARY', 'IDALIA', 'LIDIA'] #specify hurricane(s) of interest, comment out lines 28-29 if you want every hurricane from a season\n",
    "bnd = 2 #1/2 of hurricane box boundary length (degrees)\n",
    "bef_bnd = 14 # boundary for the number of days before hurricane (days)\n",
    "dur_bnd = 1 # boundary for the number of days during hurricane (days)\n",
    "aft_bnd = 14 # boundary for the number of days after hurricane (days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurricane search code\n",
    "\n",
    "Output: \n",
    "* .png plots of hurricane track and before/during/after float profile locations\n",
    "* .txt file of float WMO, cycle number, time, latitude, and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean IBTrACS CSV\n",
    "print(\"Loading IBTrACS CSV file...\")\n",
    "ibtracs_path = \"/home/jovyan/shared-public/OHW25/ArBu_proj_shared/ibtracs/ibtracs.ALL.list.v04r01.csv\"\n",
    "ibtracs = pd.read_csv(ibtracs_path, header=0, low_memory=False)\n",
    "\n",
    "# Standardize and parse columns\n",
    "ibtracs.columns = ibtracs.columns.str.strip().str.upper()\n",
    "ibtracs['SEASON'] = pd.to_numeric(ibtracs['SEASON'], errors='coerce')\n",
    "ibtracs['LAT'] = pd.to_numeric(ibtracs['LAT'], errors='coerce')\n",
    "ibtracs['LON'] = pd.to_numeric(ibtracs['LON'], errors='coerce')\n",
    "ibtracs['ISO_TIME'] = pd.to_datetime(ibtracs['ISO_TIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Filter for 2023 season\n",
    "ibtracs_seas = ibtracs[ibtracs['SEASON'] == season].dropna(subset=['LAT', 'LON', 'ISO_TIME'])\n",
    "storm_count = ibtracs_seas['NAME'].nunique()\n",
    "print(f\"Total storms found for {season}: {storm_count}\")\n",
    "\n",
    "# Output directory for profile logs\n",
    "output_dir = \"argo_profile_logs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Group by storm name\n",
    "storms = ibtracs_seas.groupby('NAME')\n",
    "\n",
    "# Process each storm\n",
    "for idx, (name, group) in enumerate(storms, start=1): \n",
    "    # comment out these two lines below if you want to process every single hurricane in a season\n",
    "    if name not in target_hurr:\n",
    "       continue  # Skip storms that are not in the target list\n",
    "    \n",
    "    print(f\"\\n[{idx}/{storm_count}] Processing storm: {name}\")\n",
    "    group = group.sort_values('ISO_TIME')\n",
    "\n",
    "    # Hurricane path coordinates\n",
    "    lats = group['LAT'].values\n",
    "    lons = group['LON'].values\n",
    "    times = pd.to_datetime(group['ISO_TIME'].values)\n",
    "\n",
    "    # Define overall bounding box and time range\n",
    "    lat_min, lat_max = lats.min() - bnd, lats.max() + bnd\n",
    "    lon_min, lon_max = lons.min() - bnd, lons.max() + bnd\n",
    "    time_start = pd.Timestamp(times.min()) - timedelta(days=bef_bnd)\n",
    "    time_end = pd.Timestamp(times.max()) + timedelta(days=aft_bnd)\n",
    "\n",
    "    # Initialize containers for Argo profiles\n",
    "    argo_before = []\n",
    "    argo_during = []\n",
    "    argo_after = []\n",
    "\n",
    "    # Loop through each hurricane point\n",
    "    for point_time, point_lat, point_lon in zip(times, lats, lons):\n",
    "        point_time = pd.Timestamp(point_time)\n",
    "\n",
    "        # Define time windows\n",
    "        before_start = point_time - timedelta(days= bef_bnd)\n",
    "        before_end   = point_time - timedelta(days= dur_bnd)\n",
    "        during_start = point_time - timedelta(days= dur_bnd)\n",
    "        during_end   = point_time + timedelta(days= dur_bnd)\n",
    "        after_start  = point_time + timedelta(days= dur_bnd)\n",
    "        after_end    = point_time + timedelta(days= aft_bnd)\n",
    "\n",
    "        # Define local bounding box\n",
    "        lat_box_min, lat_box_max = point_lat - bnd, point_lat + bnd\n",
    "        lon_box_min, lon_box_max = point_lon - bnd, point_lon + bnd\n",
    "\n",
    "        try:\n",
    "            ds = DataFetcher().region([\n",
    "                lon_box_min, lon_box_max, lat_box_min, lat_box_max, 0, 2000,\n",
    "                str(before_start.date()), str(after_end.date())\n",
    "            ]).to_xarray()\n",
    "\n",
    "            required_keys = ['LATITUDE', 'LONGITUDE', 'TIME', 'PLATFORM_NUMBER', 'CYCLE_NUMBER']\n",
    "            if not all(k in ds for k in required_keys):\n",
    "                continue\n",
    "\n",
    "            argo_times = pd.to_datetime(ds['TIME'].values)\n",
    "            lon_argo = ds['LONGITUDE'].values\n",
    "            lat_argo = ds['LATITUDE'].values\n",
    "            platform_ids = ds['PLATFORM_NUMBER'].values\n",
    "            cycle_numbers = ds['CYCLE_NUMBER'].values\n",
    "\n",
    "            # Classify profiles\n",
    "            for lon, lat, time, pid, cycle in zip(lon_argo, lat_argo, argo_times, platform_ids, cycle_numbers):\n",
    "                pid_str = pid.decode() if isinstance(pid, (bytes, bytearray)) else str(pid)\n",
    "                label = f\"{pid_str}-{cycle}\"\n",
    "                entry = f\"{label}, {time.date()}, {lat:.2f}, {lon:.2f}\"\n",
    "                if before_start <= time < before_end:\n",
    "                    argo_before.append(entry)\n",
    "                elif during_start <= time <= during_end:\n",
    "                    argo_during.append(entry)\n",
    "                elif after_start < time <= after_end:\n",
    "                    argo_after.append(entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping point due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save profile info to txt file\n",
    "    argo_before = sorted(set(argo_before))\n",
    "    argo_during = sorted(set(argo_during))\n",
    "    argo_after = sorted(set(argo_after))\n",
    "    txt_filename = os.path.join(output_dir, f\"argo_profiles_{name.lower().replace(' ', '_')}.txt\")\n",
    "    with open(txt_filename, 'w') as f:\n",
    "        f.write(f\"Argo Profiles for Hurricane: {name} {season}\\n\\n\")\n",
    "        f.write(\"[Before]\\n\")\n",
    "        f.write(\"\\n\".join(argo_before) if argo_before else \"None\\n\")\n",
    "        f.write(\"\\n\\n[During]\\n\")\n",
    "        f.write(\"\\n\".join(argo_during) if argo_during else \"None\\n\")\n",
    "        f.write(\"\\n\\n[After]\\n\")\n",
    "        f.write(\"\\n\".join(argo_after) if argo_after else \"None\\n\")\n",
    "    print(f\"   Profile info saved to: {txt_filename}\")\n",
    "\n",
    "    # Visualization (without profile labels)\n",
    "    print(\"   Generating map visualization...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([lon_min - 5, lon_max + 5, lat_min - 5, lat_max + 5])\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "\n",
    "    # Hurricane path\n",
    "    ax.plot(lons, lats, 'r-', label=f\"{name} path\")\n",
    "    ax.scatter(lons, lats, color='red', s=10)\n",
    "\n",
    "    # Argo profiles (no labels)\n",
    "    def plot_profiles(profiles, color, label_text):\n",
    "        if profiles:\n",
    "            coords = [entry.split(',')[-2:] for entry in profiles]\n",
    "            lon_p = [float(lon.strip()) for _, lon in coords]\n",
    "            lat_p = [float(lat.strip()) for lat, _ in coords]\n",
    "            ax.scatter(lon_p, lat_p, color=color, s=10, label=label_text)\n",
    "\n",
    "    plot_profiles(argo_before, 'magenta', 'Argo: Before')\n",
    "    plot_profiles(argo_during, 'lime', 'Argo: During')\n",
    "    plot_profiles(argo_after, 'blue', 'Argo: After')\n",
    "\n",
    "    plt.title(f\"{name} {season} – Hurricane Path & Argo Profiles\")\n",
    "    plt.legend()\n",
    "    output_file = f\"combined_argo_hurricane_{name.lower().replace(' ', '_')}.png\"\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    print(f\"   Map saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and format float data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data fetcher modes\n",
    "f = argopy.DataFetcher(mode='expert',ds='bgc')\n",
    "#fetch and load matching float data\n",
    "ds = f.profile((1902282, [62, 61]), (3902329, [11,12]).to_xarray()\n",
    "\n",
    "ds = ds.load() \n",
    "#apply quality control filters\n",
    "ds = ds.argo.filter_qc(QC_list=[1, 2, 8], QC_fields=['TEMP_ADJUSTED_QC', 'PSAL_ADJUSTED_QC', 'DOXY_ADJUSTED_QC','BBP700_ADJUSTED_QC','NITRATE_ADJUSTED_QC'], drop=True, mode='all', mask=False)\n",
    "#switch direction variable from string to integer (need this to match the data type of the rest of the Argo data)\n",
    "ds['DIRECTION'] = xr.where(ds['DIRECTION'] == 'A', 1, 0)  # 'A' → 1, 'D' → 0\n",
    "#convert from data point to profile format for plotting\n",
    "ds_pr = ds.argo.point2profile()\n",
    "#interpolate each profile to the same pressure grid for comparison/calculations\n",
    "ds_int = ds_pr.argo.interp_std_levels(np.arange(0,1900, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
